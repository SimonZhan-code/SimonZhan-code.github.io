

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Publications - Home</title>



<meta name="description" content="PhD student at Northwestern University working on safe reinforcement learning and cyber-physical systems">







  <link rel="canonical" href="http://localhost:4000/publications/">





  

  






  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Simon Zhan",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->

<!-- Open Graph protocol data (https://ogp.me/), used by social media -->
<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Home"> 
<meta property="og:title" content="Publications">



  <meta property="og:url" content="http://localhost:4000/publications/">





<!-- end Open Graph protocol -->

<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Home Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<!-- Support for Academicons -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<!-- favicon from https://commons.wikimedia.org/wiki/File:OOjs_UI_icon_academic-progressive.svg -->
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png"/>
<link rel="icon" type="image/svg+xml" href="http://localhost:4000/images/favicon.svg"/>
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png" sizes="32x32"/>
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-192x192.png" sizes="192x192"/>
<link rel="manifest" href="http://localhost:4000/images/manifest.json"/>
<link rel="icon" href="/images/favicon.ico"/>
<meta name="theme-color" content="#ffffff"/>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg persist"><a href="http://localhost:4000/">Home</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">CV</a></li>
          
          <li id="theme-toggle" class="masthead__menu-item persist tail">
            <a role="button" aria-labelledby="theme-icon"><i id="theme-icon" class="fa-solid fa-sun" aria-hidden="true" title="toggle theme"></i></a>
          </li>
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    



<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/simonzhan.jpg" class="author__avatar" alt="Sinong (Simon) Zhan"  fetchpriority="high" />
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Sinong (Simon) Zhan</h3>
    
    <p class="author__bio">PhD student at Northwestern University</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      <!-- Font Awesome icons / Biographic information  -->
      
        <li class="author__desktop"><i class="fas fa-fw fa-location-dot icon-pad-right" aria-hidden="true"></i>Evanston, IL</li>
      
      
        <li class="author__desktop"><i class="fas fa-fw fa-building-columns icon-pad-right" aria-hidden="true"></i>Northwestern University</li>
      
      
      
        <li><a href="mailto:SinongZhan2028@u.northwestern.edu"><i class="fas fa-fw fa-envelope icon-pad-right" aria-hidden="true"></i>Email</a></li>
      

      <!-- Font Awesome and Academicons icons / Academic websites -->
      
            
      
        <li><a href="https://scholar.google.com/citations?user=uO4dG0wAAAAJ&hl=en"><i class="ai ai-google-scholar ai-fw icon-pad-right"></i>Google Scholar</a></li>
      
      
      
      
                              
      
      
      

      <!-- Font Awesome icons / Repositories and software development -->
      
            
            
      
        <li><a href="https://github.com/SimonZhan-code"><i class="fab fa-fw fa-github icon-pad-right" aria-hidden="true"></i>GitHub</a></li>
      
            
            

      <!-- Font Awesome icons / Social media -->
              
      
      
            
      
                  
                  
      
            
            
            
      
            
                  
            
      
            
            
      
        <li><a href="https://twitter.com/SimonZHAN7"><i class="fab fa-fw fa-x-twitter icon-pad-right" aria-hidden="true"></i>X (formerly Twitter)</a></li>
      
              
      
                      
      
      
            
    </ul>
  </div>
</div>

  
  </div>


  <div class="archive">
    
      <h1 class="page__title">Publications</h1>
    
    
  <div class="wordwrap">For detailed full list of my articles, please visit <a href="https://scholar.google.com/citations?user=uO4dG0wAAAAJ&hl=en">my Google Scholar profile</a>.</div>




<div class="publications-page">
  <!-- New style rendering if publication categories are defined -->
  
    
      
      
      
      <!-- Check if category has publications -->
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      
      
    
      
      
      
      <!-- Check if category has publications -->
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      
      
    
      
      
      
      <!-- Check if category has publications -->
      
        
      
        
          
          
      
      
        
          <div class="category-section">
            <h2 class="category-title">Conference Papers</h2>
            <div class="publications-grid">
        
        
        
          
            
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2025-icml-belief-forecasting">Directly Forecasting Belief for Reinforcement Learning with Delays</a>
              </h3>
              <div class="publication-date">2025</div>
            </div>
            
            <div class="publication-venue">
              International Conference on Machine Learning (ICML)
              
                
              
            </div>
            
            
              <div class="publication-description">
                This paper presents a novel approach to directly forecast beliefs in reinforcement learning with observation delays, improving upon traditional methods by incorporating predictive capabilities into the learning process.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/pdf/2505.00546" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Directly+Forecasting+Belief+for+Reinforcement+Learning+with+Delays" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2024-neurips-vdpo">Variational Delayed Policy Optimization</a>
              </h3>
              <div class="publication-date">2024</div>
            </div>
            
            <div class="publication-venue">
              Conference on Neural Information Processing Systems (NeurIPS)
              
                
              
            </div>
            
            
              <div class="publication-description">
                Variational Delayed Policy Optimization (VDPO) reformulates delayed RL as a variational inference problem, which is further modelled as a two-step iterative optimization problem, where the first step is TD learning in the delay-free environment with a small state space, and the second step is behaviour cloning which can be addressed much more efficiently than TD learning.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/pdf/2405.14226" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <a href="https://github.com/QingyuanWuNothing/VDPO" class="pub-link">
                  <i class="fas fa-code"></i> Code
                </a>
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Variational+Delayed+Policy+Optimization" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2024-iros-trajectory-sde">Kinematics-aware Trajectory Generation and Prediction with Latent SDE</a>
              </h3>
              <div class="publication-date">2024</div>
            </div>
            
            <div class="publication-venue">
              IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
              
                
              
            </div>
            
            
              <div class="publication-description">
                This paper presents a novel approach to trajectory generation and prediction that incorporates kinematic constraints through latent stochastic differential equations, enabling more realistic and physically-consistent motion planning.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/abs/2309.09317" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Kinematics-aware+Trajectory+Generation+and+Prediction+with+Latent+SDE" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2024-icml-adrl">Boosting Long-Delayed Reinforcement Learning with Auxiliary Short-Delayed Task</a>
              </h3>
              <div class="publication-date">2024</div>
            </div>
            
            <div class="publication-venue">
              International Conference on Machine Learning (ICML)
              
                
              
            </div>
            
            
              <div class="publication-description">
                Auxiliary-Delayed Reinforcement Learning (AD-RL) leverages an auxiliary short-delayed task to accelerate the learning on a long-delayed task without compromising the performance in stochastic environments.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/abs/2402.03141" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <a href="https://github.com/QingyuanWuNothing/AD-RL" class="pub-link">
                  <i class="fas fa-code"></i> Code
                </a>
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Boosting+Long-Delayed+Reinforcement+Learning+with+Auxiliary+Short-Delayed+Task" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2024-l4dc-pixel-safe-rl">State-wise Safe Reinforcement Learning With Pixel Observations</a>
              </h3>
              <div class="publication-date">2024</div>
            </div>
            
            <div class="publication-venue">
              Learning for Dynamics and Control Conference (L4DC)
              
                
              
            </div>
            
            
              <div class="publication-description">
                In this paper, we propose a novel pixel-observation safe RL algorithm that efficiently encodes state-wise safety constraints with unknown hazard regions through the introduction of a latent barrier function learning mechanism.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/abs/2311.02227" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <a href="https://github.com/SimonZhan-code/Step-Wise_SafeRL_Pixel" class="pub-link">
                  <i class="fas fa-code"></i> Code
                </a>
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=State-wise+Safe+Reinforcement+Learning+With+Pixel+Observations" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
            
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2023-icml-safe-rl">Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments</a>
              </h3>
              <div class="publication-date">2023</div>
            </div>
            
            <div class="publication-venue">
              International Conference on Machine Learning (ICML)
              
                
              
            </div>
            
            
              <div class="publication-description">
                A safe RL approach that can jointly learn the environment and optimize the control policy, while effectively avoiding unsafe regions with safety probability optimization.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/abs/2209.15090" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <a href="https://github.com/wangyixu14/safe_unknown_control" class="pub-link">
                  <i class="fas fa-code"></i> Code
                </a>
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Enforcing+Hard+Constraints+with+Soft+Barriers%3A+Safe+Reinforcement+Learning+in+Unknown+Stochastic+Environments" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2023-iccps-certified-rl">Joint Differentiable Optimization and Verification for Certified Reinforcement Learning</a>
              </h3>
              <div class="publication-date">2023</div>
            </div>
            
            <div class="publication-venue">
              ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS)
              
                
              
            </div>
            
            
              <div class="publication-description">
                A framework that jointly conducts reinforcement learning and formal verification by formulating and solving a novel bilevel optimization problem, which is end-to-end differentiable by the gradients from the value function and certificates formulated by linear programs and semi-definite programs.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/abs/2201.12243" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <a href="https://github.com/SimonZhan-code/Certified-RL-LP" class="pub-link">
                  <i class="fas fa-code"></i> Code
                </a>
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Joint+Differentiable+Optimization+and+Verification+for+Certified+Reinforcement+Learning" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2022-ubicomp-microfluid">MicroFluID - A Reconfigurable RFID Platform for Robust Interaction Sensing Based on Microfluidics</a>
              </h3>
              <div class="publication-date">2022</div>
            </div>
            
            <div class="publication-venue">
              ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp)
              
                
              
            </div>
            
            
              <div class="publication-description">
                MicroFluID is a novel RFID artifact based on a multiple-chip structure and microfluidic switches, which informs the input state by directly reading variable ID information instead of retrieving primitive signals.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://dl.acm.org/doi/abs/10.1145/3550296" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
              
              
              
              
              
              
                <a href="https://youtu.be/7GbWFIrZ5Zw" class="pub-link">
                  <i class="fas fa-video"></i> Video
                </a>
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=MicroFluID+-+A+Reconfigurable+RFID+Platform+for+Robust+Interaction+Sensing+Based+on+Microfluidics" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2021-chi-relectrode">RElectrode: A Reconfigurable Electrode For Multi-Purpose Sensing Based on Microfluidics</a>
              </h3>
              <div class="publication-date">2021</div>
            </div>
            
            <div class="publication-venue">
              ACM Conference on Human Factors in Computing Systems (CHI)
              
                
              
            </div>
            
            
              <div class="publication-description">
                RElectrode is a reconfigurable electrode using a microfluidic technique that can change the geometry and material properties of the electrode to satisfy the needs for sensing a variety of different types of user input through touch/touchless gestures, pressure, temperature, and distinguish between different types of objects or liquids.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://doi.org/10.1145/3411764.3445652" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
              
              
              
              
              
              
                <a href="https://youtu.be/NqMHIDaU7Tg" class="pub-link">
                  <i class="fas fa-video"></i> Video
                </a>
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=RElectrode%3A+A+Reconfigurable+Electrode+For+Multi-Purpose+Sensing+Based+on+Microfluidics" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
        
        
            </div>
          </div>
        
      
    
      
      
      
      <!-- Check if category has publications -->
      
        
          
          
      
      
        
          <div class="category-section">
            <h2 class="category-title">Workshop Papers</h2>
            <div class="publications-grid">
        
        
        
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2025-shop-r1-llm-shopping">Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning</a>
              </h3>
              <div class="publication-date">2025</div>
            </div>
            
            <div class="publication-venue">
              Scaling Environments for Agents (SEA) NeurIPS 2025
              
            </div>
            
            
              <div class="publication-description">
                This paper introduces Shop-R1, a novel reinforcement learning framework aimed at enhancing the reasoning ability of LLMs for simulation of real human behavior in online shopping environments through a two-stage approach with distinct reward signals.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/pdf/2507.17842" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Shop-R1%3A+Rewarding+LLMs+to+Simulate+Human+Behavior+in+Online+Shopping+via+Reinforcement+Learning" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
            
          
            
          
            
          
            
          
            
          
          
          
          
          <div class="publication-item">
            <div class="publication-header">
              <h3 class="publication-title">
                <a href="http://localhost:4000/publication/2024-iclr-workshop-llm-autonomous-driving">Empowering Autonomous Driving with Large Language Models: A Safety Perspective</a>
              </h3>
              <div class="publication-date">2024</div>
            </div>
            
            <div class="publication-venue">
              LLMAgent Workshop at International Conference on Learning Representations (ICLR)
              
            </div>
            
            
              <div class="publication-description">
                This paper explores the integration of Large Language Models (LLMs) into autonomous driving systems, leveraging their robust common-sense knowledge and reasoning abilities to enhance driving performance and safety in long-tail unforeseen scenarios.

              </div>
            
            
            <div class="publication-links">
              
                <a href="https://arxiv.org/pdf/2312.00812" class="pub-link">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
              
              
              
              
              
              
              
              
              
              
                <!-- Auto-generate Google Scholar BibTeX link -->
                <a href="https://scholar.google.com/scholar?q=Empowering+Autonomous+Driving+with+Large+Language+Models%3A+A+Safety+Perspective" target="_blank" class="pub-link">
                  <i class="fas fa-quote-right"></i> BibTeX
                </a>
              
              
              
            </div>
          </div>
        
          
            
          
            
          
            
          
            
        
        
            </div>
          </div>
        
      
    
  
</div>

<style>
/*
====================
PUBLICATIONS PAGE STYLING
====================

This styling system matches the Selected Publications section from the homepage
and supports automatic icon generation and color coding for different link types.

SUPPORTED LINK TYPES (add these to your publication .md front matter):
- paperurl: Paper links (Red - #e74c3c)
- codeurl: Code repository links (Green - #2ecc71)  
- slidesurl: Presentation slides (Orange - #f39c12)
- projecturl: Project websites (Blue - #3498db)
- videourl: Video content (Purple - #9b59b6)
- posterurl: Poster files (Orange - #e67e22)
- bibtexurl: BibTeX files (Light Gray - #95a5a6)
- supplementurl: Supplementary materials (Default color)

ICONS USED:
- fa-file-pdf: Papers
- fa-code: Code repositories
- fa-presentation: Slides/presentations
- fa-globe: Project websites
- fa-video: Videos
- fa-image: Posters
- fa-quote-right: BibTeX
- fa-file-alt: Supplementary materials
*/

.publications-page {
  margin: 0;
  padding: 0;
}

.category-section {
  margin-bottom: 3em;
}

.category-title {
  font-size: 1.8em;
  font-weight: 700;
  color: var(--global-text-color);
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  border-bottom: 2px solid var(--global-primary-color);
}

.publications-grid {
  display: grid;
  gap: 1.5em;
}

.publication-item {
  background: var(--global-background-color);
  border: 1px solid var(--global-border-color);
  border-radius: 8px;
  padding: 24px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  transition: all 0.3s ease;
  position: relative;
}

.publication-item:hover {
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
  transform: translateY(-2px);
  border-color: var(--global-primary-color);
}

.publication-header {
  display: flex;
  justify-content: space-between;
  align-items: flex-start;
  margin-bottom: 12px;
  flex-wrap: wrap;
  gap: 10px;
}

.publication-title {
  margin: 0;
  font-size: 1.2em;
  font-weight: 600;
  line-height: 1.3;
  flex: 1;
  min-width: 300px;
}

.publication-title a {
  color: var(--global-text-color);
  text-decoration: none;
  transition: color 0.2s ease;
}

.publication-title a:hover {
  color: var(--global-link-color);
  text-decoration: underline;
}

.publication-venue {
  font-weight: 600;
  color: var(--global-primary-color);
  font-size: 0.95em;
  margin-bottom: 8px;
  display: block;
}

.publication-date {
  background: #2c3e50; /* Dark blue-gray that works on both themes */
  color: white;
  padding: 6px 12px;
  border-radius: 6px;
  font-size: 0.9em;
  font-weight: 700;
  white-space: nowrap;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.spotlight-badge {
  background: #ff6b6b;
  color: white;
  padding: 2px 8px;
  border-radius: 12px;
  font-size: 0.8em;
  font-weight: 500;
  margin-left: 8px;
  display: inline-block;
}

.publication-description {
  color: var(--global-text-color);
  font-size: 0.95em;
  line-height: 1.5;
  margin: 15px 0;
  padding-right: 60px; /* Make room for date badge */
}

.publication-links {
  display: flex;
  gap: 10px;
  flex-wrap: wrap;
  margin-top: 15px;
}

.pub-link {
  display: inline-flex;
  align-items: center;
  padding: 8px 14px;
  background: var(--global-primary-color);
  color: white;
  text-decoration: none;
  border-radius: 6px;
  font-size: 0.85em;
  font-weight: 500;
  transition: all 0.2s ease;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

.pub-link:hover {
  color: white;
  text-decoration: none;
  transform: translateY(-1px);
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
}

.pub-link i {
  margin-right: 6px;
  font-size: 0.9em;
}

/* Color coding for different link types */
.pub-link:has(i.fa-file-pdf) {
  background: #e74c3c; /* Red for papers */
}

.pub-link:has(i.fa-file-pdf):hover {
  background: #c0392b;
}

.pub-link:has(i.fa-code) {
  background: #2ecc71; /* Green for code */
}

.pub-link:has(i.fa-code):hover {
  background: #27ae60;
}

.pub-link:has(i.fa-presentation, i.fa-file-powerpoint) {
  background: #f39c12; /* Orange for presentations */
}

.pub-link:has(i.fa-presentation, i.fa-file-powerpoint):hover {
  background: #e67e22;
}

.pub-link:has(i.fa-globe, i.fa-external-link-alt) {
  background: #3498db; /* Blue for websites/projects */
}

.pub-link:has(i.fa-globe, i.fa-external-link-alt):hover {
  background: #2980b9;
}

.pub-link:has(i.fa-video) {
  background: #9b59b6; /* Purple for videos */
}

.pub-link:has(i.fa-video):hover {
  background: #8e44ad;
}

.pub-link:has(i.fa-image) {
  background: #e67e22; /* Orange for posters/images */
}

.pub-link:has(i.fa-image):hover {
  background: #d35400;
}

.pub-link:has(i.fa-quote-right) {
  background: #95a5a6; /* Light gray for BibTeX */
}

.pub-link:has(i.fa-quote-right):hover {
  background: #7f8c8d;
}

.pub-link:has(i.fa-database) {
  background: #34495e; /* Dark gray for datasets */
}

.pub-link:has(i.fa-database):hover {
  background: #2c3e50;
}

/* Responsive design */
@media (max-width: 1024px) {
  .publications-grid {
    gap: 1.2em;
  }
  
  .publication-item {
    padding: 20px;
  }
}

@media (max-width: 768px) {
  .category-title {
    font-size: 1.5em;
  }
  
  .publication-item {
    padding: 16px;
  }
  
  .publication-header {
    flex-direction: column;
    align-items: flex-start;
  }
  
  .publication-title {
    min-width: auto;
    margin-bottom: 5px;
  }
  
  .publication-venue {
    align-self: flex-start;
    text-align: left;
    white-space: normal;
  }
  
  .publication-date {
    position: static;
    align-self: flex-start;
    margin-bottom: 10px;
  }
  
  .publication-description {
    padding-right: 0;
  }
  
  .publication-links {
    justify-content: flex-start;
  }
  
  .pub-link {
    padding: 6px 12px;
    font-size: 0.8em;
  }
  
  .pub-link i {
    margin-right: 4px;
  }
}

@media (max-width: 480px) {
  .publication-item {
    padding: 12px;
  }
  
  .publication-title {
    font-size: 1.1em;
  }
  
  .publication-links {
    gap: 8px;
  }
  
  .pub-link {
    padding: 5px 10px;
    font-size: 0.75em;
  }
}
</style>




  </div>
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<a href="/sitemap/">Sitemap</a>

<!-- Support for MatJax -->
<script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script"></script>

<!-- Support for Plotly -->
<script defer src='https://cdnjs.cloudflare.com/ajax/libs/plotly.js/3.0.1/plotly.min.js'></script>

<!-- Support for Mermaid -->
<script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
    mermaid.initialize({startOnLoad:true, theme:'default'});
    await mermaid.run({querySelector:'code.language-mermaid'});
</script>

<!-- end custom footer snippets -->

        


<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="http://github.com/SimonZhan-code"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>


<div class="page__footer-copyright">
  &copy; 2025 Simon Zhan, Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.<br />
  Site last updated 2025-10-02
</div>

      </footer>
    </div>

    <script type="module" src="http://localhost:4000/assets/js/main.min.js"></script>








  </body>
</html>

