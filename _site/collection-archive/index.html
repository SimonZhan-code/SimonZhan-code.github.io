

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Posts by Collection - Home</title>



<meta name="description" content="PhD student at Northwestern University working on safe reinforcement learning and cyber-physical systems">







  <link rel="canonical" href="http://0.0.0.0:4001/collection-archive/">





  

  






  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Simon Zhan",
      "url" : "http://0.0.0.0:4001",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->

<!-- Open Graph protocol data (https://ogp.me/), used by social media -->
<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Home"> 
<meta property="og:title" content="Posts by Collection">



  <meta property="og:url" content="http://0.0.0.0:4001/collection-archive/">





<!-- end Open Graph protocol -->

<link href="http://0.0.0.0:4001/feed.xml" type="application/atom+xml" rel="alternate" title="Home Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://0.0.0.0:4001/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<!-- Support for Academicons -->
<link rel="stylesheet" href="http://0.0.0.0:4001/assets/css/academicons.css"/>

<!-- favicon from https://commons.wikimedia.org/wiki/File:OOjs_UI_icon_academic-progressive.svg -->
<link rel="apple-touch-icon" sizes="180x180" href="http://0.0.0.0:4001/images/apple-touch-icon-180x180.png"/>
<link rel="icon" type="image/svg+xml" href="http://0.0.0.0:4001/images/favicon.svg"/>
<link rel="icon" type="image/png" href="http://0.0.0.0:4001/images/favicon-32x32.png" sizes="32x32"/>
<link rel="icon" type="image/png" href="http://0.0.0.0:4001/images/favicon-192x192.png" sizes="192x192"/>
<link rel="manifest" href="http://0.0.0.0:4001/images/manifest.json"/>
<link rel="icon" href="/images/favicon.ico"/>
<meta name="theme-color" content="#ffffff"/>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg persist"><a href="http://0.0.0.0:4001/">Home</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://0.0.0.0:4001/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://0.0.0.0:4001/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://0.0.0.0:4001/cv/">CV</a></li>
          
          <li id="theme-toggle" class="masthead__menu-item persist tail">
            <a role="button" aria-labelledby="theme-icon"><i id="theme-icon" class="fa-solid fa-sun" aria-hidden="true" title="toggle theme"></i></a>
          </li>
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    



<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://0.0.0.0:4001/images/simonzhan.jpg" class="author__avatar" alt="Sinong (Simon) Zhan"  fetchpriority="high" />
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Sinong (Simon) Zhan</h3>
    
    <p class="author__bio">PhD student at Northwestern University</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      <!-- Font Awesome icons / Biographic information  -->
      
        <li class="author__desktop"><i class="fas fa-fw fa-location-dot icon-pad-right" aria-hidden="true"></i>Evanston, IL</li>
      
      
        <li class="author__desktop"><i class="fas fa-fw fa-building-columns icon-pad-right" aria-hidden="true"></i>Northwestern University</li>
      
      
      
        <li><a href="mailto:SinongZhan2028@u.northwestern.edu"><i class="fas fa-fw fa-envelope icon-pad-right" aria-hidden="true"></i>Email</a></li>
      

      <!-- Font Awesome and Academicons icons / Academic websites -->
      
            
      
        <li><a href="https://scholar.google.com/citations?user=uO4dG0wAAAAJ&hl=en"><i class="ai ai-google-scholar ai-fw icon-pad-right"></i>Google Scholar</a></li>
      
      
      
      
                              
      
      
      

      <!-- Font Awesome icons / Repositories and software development -->
      
            
            
      
        <li><a href="https://github.com/SimonZhan-code"><i class="fab fa-fw fa-github icon-pad-right" aria-hidden="true"></i>GitHub</a></li>
      
            
            

      <!-- Font Awesome icons / Social media -->
              
      
      
            
      
                  
                  
      
            
            
            
      
            
                  
            
      
            
            
      
        <li><a href="https://twitter.com/SimonZHAN7"><i class="fab fa-fw fa-x-twitter icon-pad-right" aria-hidden="true"></i>X (formerly Twitter)</a></li>
      
              
      
                      
      
      
            
    </ul>
  </div>
</div>

  
  </div>


  <div class="archive">
    
      <h1 class="page__title">Posts by Collection</h1>
    
    



  
    
    
      <h2 id="portfolio" class="archive__subtitle">portfolio</h2>
      
    
  
  

  
  

  
    
    
      <h2 id="publications" class="archive__subtitle">publications</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2021-chi-relectrode" rel="permalink">RElectrode: A Reconfigurable Electrode For Multi-Purpose Sensing Based on Microfluidics
</a>
      
    </h2>
    
    

        
          <p>Published in <i>ACM Conference on Human Factors in Computing Systems (CHI)</i>, 2021 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>RElectrode is a reconfigurable electrode using a microfluidic technique that can change the geometry and material properties of the electrode to satisfy the needs for sensing a variety of different types of user input through touch/touchless gestures, pressure, temperature, and distinguish between different types of objects or liquids.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{sun2021relectrode, title={RElectrode: A Reconfigurable Electrode For Multi-Purpose Sensing Based on Microfluidics}, author={Sun, Wei and Chen, Yanjun and Zhan, Simon and Han, Teng and Tian, Feng and Wang, Hongan and Yang, Xing-Dong}, booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems}, year={2021}, doi={10.1145/3411764.3445652}, url={https://doi.org/10.1145/3411764.3445652} }<br /><a href="https://doi.org/10.1145/3411764.3445652">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2022-ubicomp-microfluid" rel="permalink">MicroFluID - A Reconfigurable RFID Platform for Robust Interaction Sensing Based on Microfluidics
</a>
      
    </h2>
    
    

        
          <p>Published in <i>ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>MicroFluID is a novel RFID artifact based on a multiple-chip structure and microfluidic switches, which informs the input state by directly reading variable ID information instead of retrieving primitive signals.</p>
</p>
    
    
    
      <p>Recommended citation: @article{sun2022microfluid, title={MicroFluID - A Reconfigurable RFID Platform for Robust Interaction Sensing Based on Microfluidics}, author={Sun, Wei and Chen, Yuwen and Chen, Yanjun and Zhang, Xiaopeng and Zhan, Simon and Li, Yixin and Wu, Jiecheng and Han, Teng and Mi, Haipeng and Wang, Jingxian and Tian, Feng and Yang, Xing-Dong}, journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies}, year={2022}, doi={10.1145/3550296}, url={https://dl.acm.org/doi/abs/10.1145/3550296} }<br /><a href="https://dl.acm.org/doi/abs/10.1145/3550296">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2023-iccps-certified-rl" rel="permalink">Joint Differentiable Optimization and Verification for Certified Reinforcement Learning
</a>
      
    </h2>
    
    

        
          <p>Published in <i>ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS)</i>, 2023 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>A framework that jointly conducts reinforcement learning and formal verification by formulating and solving a novel bilevel optimization problem, which is end-to-end differentiable by the gradients from the value function and certificates formulated by linear programs and semi-definite programs.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{wang2023joint, title={Joint Differentiable Optimization and Verification for Certified Reinforcement Learning}, author={Wang, Yixuan and Zhan, Sinong Simon and Wang, Zhilu and Huang, Chao and Wang, Zhaoran and Yang, Zhuoran and Zhu, Qi}, booktitle={ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS)}, year={2023}, url={https://arxiv.org/abs/2201.12243} }<br /><a href="https://arxiv.org/abs/2201.12243">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2023-icml-safe-rl" rel="permalink">Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments
</a>
      
    </h2>
    
    

        
          <p>Published in <i>International Conference on Machine Learning (ICML)</i>, 2023 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>A safe RL approach that can jointly learn the environment and optimize the control policy, while effectively avoiding unsafe regions with safety probability optimization.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{wang2023enforcing, title={Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments}, author={Wang, Yixuan and Zhan, Sinong Simon and Jiao, Ruochen and Wang, Zhilu and Jin, Wanxin and Yang, Zhuoran and Wang, Zhaoran and Huang, Chao and Zhu, Qi}, booktitle={International Conference on Machine Learning (ICML)}, year={2023}, url={https://arxiv.org/abs/2209.15090} }<br /><a href="https://arxiv.org/abs/2209.15090">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2024-iclr-workshop-llm-autonomous-driving" rel="permalink">Empowering Autonomous Driving with Large Language Models: A Safety Perspective
</a>
      
    </h2>
    
    

        
          <p>Published in <i>LLMAgent Workshop at International Conference on Learning Representations (ICLR)</i>, 2024 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper explores the integration of Large Language Models (LLMs) into autonomous driving systems, leveraging their robust common-sense knowledge and reasoning abilities to enhance driving performance and safety in long-tail unforeseen scenarios.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{wang2024empowering, title={Empowering Autonomous Driving with Large Language Models: A Safety Perspective}, author={Wang, Yixuan and Jiao, Ruochen and Zhan, Simon and Lang, Chengtian and Huang, Chao and Wang, Zhaoran and Yang, Zhuoran and Zhu, Qi}, booktitle={LLMAgent Workshop at International Conference on Learning Representations (ICLR)}, year={2024}, url={https://arxiv.org/abs/2312.00812} }<br /><a href="https://arxiv.org/pdf/2312.00812">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2024-l4dc-pixel-safe-rl" rel="permalink">State-wise Safe Reinforcement Learning With Pixel Observations
</a>
      
    </h2>
    
    

        
          <p>Published in <i>Learning for Dynamics and Control Conference (L4DC)</i>, 2024 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>In this paper, we propose a novel pixel-observation safe RL algorithm that efficiently encodes state-wise safety constraints with unknown hazard regions through the introduction of a latent barrier function learning mechanism.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{zhan2024statewise, title={State-wise Safe Reinforcement Learning With Pixel Observations}, author={Zhan, Sinong Simon and Wang, Yixuan and Wu, Qingyuan and Jiao, Ruochen and Huang, Chao and Zhu, Qi}, booktitle={Learning for Dynamics and Control Conference (L4DC)}, year={2024}, url={https://arxiv.org/abs/2311.02227} }<br /><a href="https://arxiv.org/abs/2311.02227">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2024-icml-adrl" rel="permalink">Boosting Long-Delayed Reinforcement Learning with Auxiliary Short-Delayed Task
</a>
      
    </h2>
    
    

        
          <p>Published in <i>International Conference on Machine Learning (ICML)</i>, 2024 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>Auxiliary-Delayed Reinforcement Learning (AD-RL) leverages an auxiliary short-delayed task to accelerate the learning on a long-delayed task without compromising the performance in stochastic environments.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{wu2024boosting, title={Boosting Long-Delayed Reinforcement Learning with Auxiliary Short-Delayed Task}, author={Wu, Qingyuan and Zhan, Sinong Simon and Wang, Yixuan and Wang, Yuhui and Lin, Chung-Wei and Lv, Chen and Zhu, Qi and Schmidhuber, JÃ¼rgen and Huang, Chao}, booktitle={International Conference on Machine Learning (ICML)}, year={2024}, url={https://arxiv.org/abs/2402.03141} }<br /><a href="https://arxiv.org/abs/2402.03141">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2024-iros-trajectory-sde" rel="permalink">Kinematics-aware Trajectory Generation and Prediction with Latent SDE
</a>
      
    </h2>
    
    

        
          <p>Published in <i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2024 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper presents a novel approach to trajectory generation and prediction that incorporates kinematic constraints through latent stochastic differential equations, enabling more realistic and physically-consistent motion planning.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{zhan2024kinematics, title={Kinematics-aware Trajectory Generation and Prediction with Latent SDE}, author={Zhan, Sinong Simon and Wu, Qingyuan and Wang, Yixuan and Huang, Chao and Zhu, Qi}, booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, year={2024}, url={https://arxiv.org/abs/2309.09317} }<br /><a href="https://arxiv.org/abs/2309.09317">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2024-neurips-vdpo" rel="permalink">Variational Delayed Policy Optimization
</a>
      
    </h2>
    
    

        
          <p>Published in <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2024 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>Variational Delayed Policy Optimization (VDPO) reformulates delayed RL as a variational inference problem, which is further modelled as a two-step iterative optimization problem, where the first step is TD learning in the delay-free environment with a small state space, and the second step is behaviour cloning which can be addressed much more efficiently than TD learning.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{wu2024variational, title={Variational Delayed Policy Optimization}, author={Wu, Qingyuan and Zhan, Sinong Simon and Wang, Yixuan and Wang, Yuhui and Lin, Chung-Wei and Lv, Chen and Zhu, Qi and Huang, Chao}, booktitle={Advances in Neural Information Processing Systems (NeurIPS)}, year={2024}, note={Spotlight}, url={https://arxiv.org/abs/2405.14226} }<br /><a href="https://arxiv.org/pdf/2405.14226">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2025-icml-belief-forecasting" rel="permalink">Directly Forecasting Belief for Reinforcement Learning with Delays
</a>
      
    </h2>
    
    

        
          <p>Published in <i>International Conference on Machine Learning (ICML)</i>, 2025 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper presents a novel approach to directly forecast beliefs in reinforcement learning with observation delays, improving upon traditional methods by incorporating predictive capabilities into the learning process.</p>
</p>
    
    
    
      <p>Recommended citation: @inproceedings{zhan2025directly, title={Directly Forecasting Belief for Reinforcement Learning with Delays}, author={Zhan, Sinong Simon and Wu, Qingyuan and Wang, Yixuan and Huang, Chao and Zhu, Qi}, booktitle={International Conference on Machine Learning (ICML)}, year={2025}, url={https://arxiv.org/abs/2505.00546} }<br /><a href="https://arxiv.org/pdf/2505.00546">Download Paper</a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://0.0.0.0:4001/publication/2025-shop-r1-llm-shopping" rel="permalink">Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning
</a>
      
    </h2>
    
    

        
          <p>Published in <i>Scaling Environments for Agents (SEA) NeurIPS 2025</i>, 2025 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper introduces Shop-R1, a novel reinforcement learning framework aimed at enhancing the reasoning ability of LLMs for simulation of real human behavior in online shopping environments through a two-stage approach with distinct reward signals.</p>
</p>
    
    
    
      <p>Recommended citation: @article{zhang2025shop, title={Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning}, author={Zhang, Yimeng and Wang, Tian and Gesi, Jiri and Wang, Ziyi and Lu, Yuxuan and Lin, Jiacheng and Zhan, Sinong and Gao, Vianne and Jiao, Ruochen and Liu, Junze and Qian, Kun and Tang, Yuxin and Xue, Ran and Zhang, Houyu and Cui, Qingjun and Guo, Yufan and Wang, Dakuo}, journal={arXiv preprint arXiv:2507.17842}, year={2025}, url={https://arxiv.org/abs/2507.17842} }<br /><a href="https://arxiv.org/pdf/2507.17842">Download Paper</a></p>
    

  </article>
</div>

    
  

  
    
    
      <h2 id="talks" class="archive__subtitle">talks</h2>
      
    
  
  

  
    
    
      <h2 id="teaching" class="archive__subtitle">teaching</h2>
      
    
  
  

  </div>
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<a href="/sitemap/">Sitemap</a>

<!-- Support for MatJax -->
<script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script"></script>

<!-- Support for Plotly -->
<script defer src='https://cdnjs.cloudflare.com/ajax/libs/plotly.js/3.0.1/plotly.min.js'></script>

<!-- Support for Mermaid -->
<script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
    mermaid.initialize({startOnLoad:true, theme:'default'});
    await mermaid.run({querySelector:'code.language-mermaid'});
</script>

<!-- end custom footer snippets -->

        


<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="http://github.com/SimonZhan-code"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="http://0.0.0.0:4001/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>


<div class="page__footer-copyright">
  &copy; 2025 Simon Zhan, Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.<br />
  Site last updated 2025-10-02
</div>

      </footer>
    </div>

    <script type="module" src="http://0.0.0.0:4001/assets/js/main.min.js"></script>








  </body>
</html>

