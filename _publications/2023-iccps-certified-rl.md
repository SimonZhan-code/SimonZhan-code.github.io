---
title: "Joint Differentiable Optimization and Verification for Certified Reinforcement Learning"
collection: publications
category: conferences
permalink: /publication/2023-iccps-certified-rl
excerpt: 'A framework that jointly conducts reinforcement learning and formal verification by formulating and solving a novel bilevel optimization problem, which is end-to-end differentiable by the gradients from the value function and certificates formulated by linear programs and semi-definite programs.'
date: 2023-03-01
venue: 'ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS)'
paperurl: 'https://arxiv.org/abs/2201.12243'
codeurl: 'https://github.com/SimonZhan-code/Certified-RL-LP'
citation: '@inproceedings{wang2023joint,
  title={Joint Differentiable Optimization and Verification for Certified Reinforcement Learning},
  author={Wang, Yixuan and Zhan, Sinong Simon and Wang, Zhilu and Huang, Chao and Wang, Zhaoran and Yang, Zhuoran and Zhu, Qi},
  booktitle={ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS)},
  year={2023},
  url={https://arxiv.org/abs/2201.12243}
}'
---

This paper presents a novel framework that jointly conducts reinforcement learning and formal verification by formulating and solving a bilevel optimization problem. The approach is end-to-end differentiable through gradients from the value function and certificates formulated by linear programs and semi-definite programs, enabling certified safe policy learning.

[Download paper here](https://arxiv.org/abs/2201.12243)

[Code available here](https://github.com/SimonZhan-code/Certified-RL-LP)

**Authors:** Yixuan Wang*, Simon Sinong Zhan*, Zhilu Wang, Chao Huang, Zhaoran Wang, Zhuoran Yang, Qi Zhu (*equal contribution)